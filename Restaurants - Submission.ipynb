{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "\n",
    "!conda install -c conda-forge geopy --yes \n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore ssl certeficate error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "print('SSL certificate errors ignored.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from the Wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = pd.read_html('https://en.wikipedia.org/wiki/List_of_national_capitals',header=0)\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check how mant capital cities of world countries are there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Notes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Notes', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Columns of city and country according to standard naming conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'City/Town':'City','Country/Territory':'Country'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the capitals of the World Countries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing parentheses and all data within using Pandas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'] = df['City'].str.replace(r\"\\(.*?\\)\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the lat and long coordinate columns to the data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lat\"] = \"\"\n",
    "df[\"lng\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the operation of geop: Use geopy library to get the latitude and longitude values of Abu Dhabi (the Capital of United Arab Emirates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = df ['City'].values[2]\n",
    "geolocator = Nominatim(user_agent=\"World_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Abu Dhabi are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the coordinates data of the World countriesâ€™ Capitals.\n",
    "If an exception occurs, insert nan values in the coordinates columns and print the word \"nan inserted\".\n",
    "Please be patient and wait until the sentence 'OK. Finished' is printed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for x in df['City']:  \n",
    "        address = x\n",
    "        try:         \n",
    "            geolocator = Nominatim(user_agent=\"World_explorer\")\n",
    "            location = geolocator.geocode(address)\n",
    "            latitude = location.latitude\n",
    "            longitude = location.longitude\n",
    "            #df.loc[j,'lat']=latitude\n",
    "            #df.loc[j,'lng']=longitude\n",
    "            #print ('j=', j, 'city=' , df.loc[j,'City'], 'lat=', df.loc[j,'lat'], 'long =', df.loc[j,'lng'])\n",
    "            \n",
    "            #print ('j=', j)\n",
    "            #print ('address=', x)\n",
    "            \n",
    "            #print (df.loc[j,'latdf['CityCoordinates'] = df['city'].apply(geolocator.geocode, timeout=1000000).apply(lambda x: eval_results(x))\n",
    "            #print (df.loc[j,'lng'])\n",
    "            #print('The geograpical coordinate of  Cities are {}, {}.'.format(latitude, longitude))\n",
    "            #j=j+1\n",
    "            # print ('j=', j)\n",
    "        except:\n",
    "            #print ('exception',address)\n",
    "            df.loc[j,'lat']='nan'\n",
    "            df.loc[j,'lng']='nan'\n",
    "            #print ('j=', j, 'city=' , df.loc[j,'City'], 'lat=', df.loc[j,'lat'], 'long =', df.loc[j,'lng'])\n",
    "            print ('nan inserted')\n",
    "            j=j+1\n",
    "            continue\n",
    "        df.loc[j,'lat']=latitude\n",
    "        df.loc[j,'lng']=longitude\n",
    "        print ('j=', j, 'city=' , df.loc[j,'City'], 'lat=', df.loc[j,'lat'], 'long =', df.loc[j,'lng'])\n",
    "        j=j+1\n",
    "print ('OK. Finished')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with nan values in latitude or longitude fields (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df.dropna(subset = [\"lat\"], inplace=True)\n",
    "#df.dropna(inplace=True)\n",
    "#df.info()\n",
    "#df2= df.dropna(how='any',inplace=True) \n",
    "#df.dropna(axis=0, subset=['lat'],inplace=True)\n",
    "df = df[df.lat != 'nan']\n",
    "df = df[df.lat != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset df index in case nan rows were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True,inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a World Map with all Countries' Capital Cities superimposed on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create map of World counteries using latitude and longitude values\n",
    "\n",
    "map_World = folium.Map(location=[latitude, longitude], zoom_start=1.9)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, label in zip(df['lat'], df['lng'], df['City']):\n",
    "    try:\n",
    "        \n",
    "        label = folium.Popup(label, parse_html=True)\n",
    "        folium.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=1,\n",
    "            popup=label,\n",
    "            color='blue',\n",
    "            fill=True,\n",
    "            fill_color='#3186cc',\n",
    "            fill_opacity=0.7,\n",
    "            parse_html=False).add_to(map_World) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "map_World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring  the World Capital Cities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to start utilizing the Foursquare API to explore the World capital cities and segment them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Foursquare Credentials and Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'JSTSDMFW35QUZS4STIZJVDT0ZJ20MEVH3INEGWEJOL2FEKOF' # your Foursquare ID\n",
    "CLIENT_SECRET = 'FDUOZO42D4FJWCTHTBGHTP5DV0UAUNVXXZCWBRBZJALD0VLW' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the second country in our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the country's  capital city name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[2, 'City']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Country's capital latitude and longitude values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_latitude = df.loc[2, 'lat'] # neighborhood latitude value\n",
    "neighborhood_longitude = df.loc[2, 'lng'] # neighborhood longitude value\n",
    "\n",
    "neighborhood_name = df.loc[2, 'City'] # neighborhood name\n",
    "\n",
    "\n",
    "print('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n",
    "                                                               neighborhood_latitude, \n",
    "                                                               neighborhood_longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now, let's get the top 100 venues that are in Abu Dhabi  within a radius of 6 km."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create the GET request URL. Name your URL url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 100\n",
    "LIMIT = 100 # limit of number of venues returned by Foursquare API\n",
    "\n",
    "radius = 60000 # define radius\n",
    "\n",
    "# create URL\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    neighborhood_latitude, \n",
    "    neighborhood_longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "url # display URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the GET request and examine the resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(url).json()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a function that extracts the category of the venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts the category of the venue\n",
    "\n",
    "def get_category_type(row):\n",
    "\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the json and structure it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = results['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues = json_normalize(venues) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to repeat the same process to all the country capitals in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=60000):     \n",
    "    LIMIT =100\n",
    "    limit= 100\n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        # print(name)\n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "             CLIENT_SECRET, \n",
    "             VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "        try:\n",
    "            # make the GET request      \n",
    "            results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "            # return only relevant information for each nearby venue\n",
    "        except:\n",
    "            print ('exception')\n",
    "            continue\n",
    "        venues_list.append([(\n",
    "                name, \n",
    "                lat, \n",
    "                lng, \n",
    "                v['venue']['name'], \n",
    "                v['venue']['location']['lat'], \n",
    "                v['venue']['location']['lng'],  \n",
    "                v['venue']['categories'][0]['name']) for v in results])\n",
    "        #except:\n",
    "           # print ('exception')\n",
    "           # continue\n",
    "            \n",
    "        nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "        nearby_venues.columns = ['World Capital', \n",
    "                        'Latitude', \n",
    "                        'Longitude', \n",
    "                        'Venue', \n",
    "                        'Venue Latitude', \n",
    "                        'Venue Longitude', \n",
    "                        'Venue Category']    \n",
    "            \n",
    "    print ('finished')\n",
    "    return(nearby_venues) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above function on each capital and create a new dataframe called World_venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('please wait until a Finish message is displayed')\n",
    "World_venues = getNearbyVenues(names=df['City'],\n",
    "                                   latitudes=df['lat'],\n",
    "                                   longitudes=df['lng']\n",
    "                                  )\n",
    "print ('Finished')\n",
    "World_venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letus check for douplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateDFRow = World_venues[World_venues.duplicated()]\n",
    "df_duplicateDFRow =pd.DataFrame(duplicateDFRow)\n",
    "df_duplicateDFRow\n",
    "#print(duplicateDFRow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the size and contents of the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(World_venues.shape)\n",
    "World_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_venues.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letus drop duplicate venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_venues = World_venues.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the size after dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_venues.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many venues were returned for each country capital in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_venues.groupby('World Capital').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfa = pd.DataFrame(World_venues.groupby('World Capital').count())\n",
    "#dfa\n",
    "dfa.reindex()\n",
    "#dfa.plot.barh(x='World Capital', y='Venue', title=\"Total number of venues for each national capital city\");\n",
    "\n",
    "#plot.show(block=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "plot.rcParams[\"figure.figsize\"] = [5, 60]\n",
    "dfa= dfa.reset_index()\n",
    "dfa.plot.barh(x=\"World Capital\" , y=\"Venue\", rot=0, title=\"Total number of venues for each national capital city\");\n",
    "\n",
    "plot.show(block=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print( dfa.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfa.plot.hist( by='Venue', bins=200,log=True, figsize = (15,5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb=dfa['Venue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.plot.hist( by='Venue', bins=50,log=True, figsize = (15,6) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out how many unique categories can be curated from all the returned venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(World_venues['Venue Category'].unique())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let Us display the  uniques categorie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from pandas import DataFrame\n",
    "uniques_categories= DataFrame (World_venues['Venue Category'].unique())\n",
    "#uniques_categories\n",
    "uniques_categories.sort_values(by=[0])\n",
    "uniques_categories.reindex() \n",
    "uniques_categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us calculate the total number of venues in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Venues_category_Statistics= DataFrame (World_venues['Venue Category'].value_counts())\n",
    "\n",
    "#Venues_category_Statistics.reset_index()\n",
    "#gapminder.columns = ['country','year','population','continent','life_exp','gdp_per_cap']\n",
    "#Venues_category_Statistics.reset_index() \n",
    "#Venues_category_Statistics.reindex()\n",
    "\n",
    "#Venues_category_Statistics.reset_index()\n",
    "#Venues_category_Statistics.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Venues_category_Statistics_a = Venues_category_Statistics.reset_index()\n",
    "Venues_category_Statistics_a = Venues_category_Statistics \n",
    "\n",
    "#Venues_category_Statistics_a.reindex()\n",
    "Venues_category_Statistics_a.reset_index(inplace = True)\n",
    "Venues_category_Statistics_a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Venues_category_Statistics_b=Venues_category_Statistics_a.rename(columns={'index':'Venue Category','Venue Category':'Count_Category' })\n",
    "                 \n",
    "Venues_category_Statistics_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select needed rows only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Venues_category_Statistics_c= Venues_category_Statistics_b.loc[(Venues_category_Statistics_b['Venue Category'] == 'Hotel') | (Venues_category_Statistics_b['Venue Category'] == 'Coffee Shop')| (Venues_category_Statistics_b['Venue Category'] == 'Restaurant')]\n",
    "Venues_category_Statistics_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Venues_category_Statistics_c.plot.bar(x='Venue Category', y='Count_Category', rot=0,figsize = (8,4),fontsize =14)\n",
    "ax.set_ylabel('Count_Category')\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.5}'.format(Decimal(str(p.get_height()))), (p.get_x(), p.get_height()))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Venues_category_Statistics_c.info()\n",
    "ss=Venues_category_Statistics_c.sum()\n",
    "print ( ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us exclude all venues except Hotels, Coffee Shops and Restaurants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#indexNames = World_venues [ (World_venues ['Venue Category']  !=  â€˜Hotelâ€™)   ].index\n",
    "#World_venues.drop(indexNames , inplace=False)\n",
    "#World_venues [ World_venues ['Venue Category'].isin ('Hotel','Coffee Shop' )] \n",
    "tt = ['Hotel' , 'Coffee Shop','Restaurant' ]\n",
    "World_venues1= World_venues[World_venues['Venue Category'].isin(tt)]\n",
    "#reset_index(drop=True,inplace=True )\n",
    "World_venues1.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letus reset the index of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "World_venues1.reset_index(drop=True,inplace=True )\n",
    "World_venues1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_venues1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_venues1=World_venues1.drop_duplicates()\n",
    "World_venues1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "World_venues=World_venues1\n",
    "World_venues.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Each World Country Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do  one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "World_onehot = pd.get_dummies(World_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "World_onehot['World Capital'] = World_venues['World Capital'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [World_onehot.columns[-1]] + list(World_onehot.columns[:-1])\n",
    "World_onehot = World_onehot[fixed_columns]\n",
    "\n",
    "World_onehot.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_onehot.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's group rows by World Capital Cities and by taking the mean of the frequency of occurrence of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "World_grouped = World_onehot.groupby('World Capital').mean().reset_index()\n",
    "World_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print each capital city  along with the  venues of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 3\n",
    "\n",
    "for hood in World_grouped['World Capital']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = World_grouped[World_grouped['World Capital'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put that into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 3\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['World Capital']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "World_Capital_venues_sorted = pd.DataFrame(columns=columns)\n",
    "World_Capital_venues_sorted['World Capital'] = World_grouped['World Capital']\n",
    "\n",
    "for ind in np.arange(World_grouped.shape[0]):\n",
    "    World_Capital_venues_sorted.iloc[ind, 1:] = return_most_common_venues(World_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "World_Capital_venues_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_Capital_venues_sorted =World_Capital_venues_sorted .drop_duplicates()\n",
    "World_Capital_venues_sorted.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster World Capital Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run k-means to cluster the world capital cities into 3 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_grouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 3\n",
    "\n",
    "World_grouped_clustering = World_grouped.drop('World Capital', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(algorithm = 'full', init=\"k-means++\",n_init=1000, max_iter=600, n_clusters=kclusters, random_state= 42).fit(World_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "#kmeans.labels_ \n",
    "labels = kmeans.labels_\n",
    "print(labels)\n",
    "#World_grouped_clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = kmeans.labels_\n",
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "World_grouped[\"Clus_km\"] = labels\n",
    "World_grouped.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_grouped_clustering.loc [:, 'Hotel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily check the centroid values by averaging the features in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_grouped.groupby('Clus_km').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "World_grouped.groupby('Clus_km').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets look at the distribution of market segment based on the number of Hptels, Coffeeshops and Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = World_grouped_clustering.values[:,0:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diisribution of cities based on the frequency of the hotels and coffeshop venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(9, 9))\n",
    "area = 250* np.pi * ( X[:, 2])**2\n",
    "plt.scatter(X[:, 0], X[:, 1], s=area, c=  labels1.astype(np.float), alpha= .5,  cmap =\"rainbow\", edgecolor='black')\n",
    "plt.xlabel('Coffee Shop', fontsize=20)\n",
    "plt.ylabel('Hotel', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(9, 9))\n",
    "area = 250* np.pi * ( X[:, 0])**2\n",
    "plt.scatter(X[:, 1], X[:, 2], s=area, c=  labels1.astype(np.float), alpha= .5,  cmap =\"rainbow\", edgecolor='black')\n",
    "plt.xlabel('Hotel', fontsize=20)\n",
    "plt.ylabel('Restaurant', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = plt.figure(1, figsize=(9, 9))\n",
    "area = 250* np.pi * ( X[:, 1])**2\n",
    "plt.scatter(X[:, 0], X[:, 2], s=area, c=  labels1.astype(np.float), alpha= .5, cmap=plt.cm.rainbow, edgecolor='black')\n",
    "plt.xlabel('Coffee SHop', fontsize=20)\n",
    "plt.ylabel('Restaurant', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "fig = plt.figure(1, figsize=(10, 10))\n",
    "\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "plt.cla()\n",
    "#plt.fontsize = 25\n",
    "ax.zaxis.set_tick_params(labelsize=14)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.yaxis.set_tick_params(labelsize=14)\n",
    "ax.zaxis.set_tick_params(grid_label =16)\n",
    "plt.xlabel('Coffee Shop', fontsize=20)\n",
    "plt.ylabel('Hotel', fontsize=20)\n",
    "#plt.zlabel('Restaurant', fontsize=20)\n",
    "\n",
    "ax.set_zlabel('Restaurant', fontsize=20)\n",
    "ax.clabel( inline=True, fontsize=30)\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c= labels1 .astype(np.float),s=250, alpha =.3, cmap=plt.cm.rainbow,edgecolor='black' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us filter the df to get the cities that have venue data onlt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfa = df_A.drop_duplicates(subset=['my_icon_number'])\n",
    "#dfb = df_B.drop_duplicates(subset=['my_icon_number'])\n",
    "dfa = dfa.drop_duplicates(subset=['World Capital'])\n",
    "#dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#World_Capital_merged = World_Capital_merged.join(World_Capital_venues_sorted.set_index('World Capital'), on='City')\n",
    "#tt =pd.DataFrame(dfa)\n",
    "#df = df.join(tt.set_index('World Capital'), on='City')\n",
    "\n",
    "dfb = pd.merge(dfa, df, left_on='World Capital',right_on='City',suffixes=(' ', ' '),  how='inner')\n",
    "\n",
    "dfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb=dfb.drop_duplicates()\n",
    "dfb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a new dataframe that includes the cluster as well as the  3 venues for of interest the element world capital cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "World_Capital_venues_sorted.insert(1, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "World_Capital_merged = dfb\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood'CommonName'\n",
    "World_Capital_merged = World_Capital_merged.join(World_Capital_venues_sorted.set_index('World Capital'), on='City')\n",
    "\n",
    "World_Capital_merged  # che#ck the last columns!\n",
    "#World_Capital_venues_sorted\n",
    "#World_Capital_merged \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the nan value from cluster lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_Capital_merged.dropna (subset=['Cluster Labels'], inplace=True)\n",
    "World_Capital_merged.head(300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_Capital_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_Capital_merged=World_Capital_merged.drop_duplicates()\n",
    "World_Capital_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizing the resulting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop nan values from cluster lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#World_Capital_merged.dropna( inplace=True)\n",
    "#World_Capital_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=2)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(World_Capital_merged['lat'], World_Capital_merged['lng'], World_Capital_merged['City'], World_Capital_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "   \n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=2,\n",
    "        popup=label,\n",
    "        color=rainbow[int(cluster-1)],\n",
    "        #olor='blue',\n",
    "        fill=True,\n",
    "        fill_color=rainbow[int(cluster-1)],\n",
    "        #fill_color='#3186cc',\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To visualize  the map please copy the Giyhub-link of this notebook and past it in the following website:\n",
    "https://nbviewer.jupyter.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let up print some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "World_onehot_grouped = World_onehot.groupby(by=\"World Capital\").agg({'Coffee Shop': 'sum','Hotel': 'sum','Restaurant': 'sum'})\n",
    "World_onehot_grouped =pd.DataFrame(World_onehot_grouped).reset_index() \n",
    "World_onehot_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total target venues in each capital city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_onehot_grouped1 = World_onehot_grouped [\"Coffee Shop\"] + World_onehot_grouped[\"Hotel\"]+ World_onehot_grouped[\"Restaurant\"]\n",
    "World_onehot_grouped1\n",
    "World_onehot_grouped['total']=World_onehot_grouped1\n",
    "World_onehot_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include other details of each capital city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged = pd.merge(World_onehot_grouped, World_Capital_merged, left_on='World Capital', right_on ='City')\n",
    "#df_merge_difkey = pd.merge(df_row, df3, left_on='id', right_on='id')\n",
    "World_onehot_grouped_merged.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#World_venues = World_venues.drop_duplicates()\n",
    "World_onehot_grouped_merged=World_onehot_grouped_merged.drop_duplicates()\n",
    "World_onehot_grouped_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drow a histogram that depicts the distribution of features oneach city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged_W = World_onehot_grouped_merged [['World Capital_x', 'Hotel', 'Coffee Shop' , 'Restaurant' , 'total']] \n",
    "World_onehot_grouped_merged_W.hist( bins=25,log=False, figsize = (15,8) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drow a barchart that depicts the distribution of features oneach city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "plot.rcParams[\"figure.figsize\"] = [10, 300]\n",
    "#dfa= dfa.reset_index()\n",
    "World_onehot_grouped_merged_W = World_onehot_grouped_merged [['World Capital_x', 'Hotel', 'Coffee Shop' , 'Restaurant' , 'total']] \n",
    "World_onehot_grouped_merged_W.plot.barh(x=\"World Capital_x\" ,  rot=0, title=\"Number of Selected Features' Venues in each national capital city\");\n",
    "plot.grid()\n",
    "#plot.show(block=True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us drow heat map for total venues Worldwide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged['marker_color'] = pd.cut(World_onehot_grouped_merged['total'], bins=3, \n",
    "                              labels=[ ' #FFA500','#1E90FF', 'red' ])\n",
    "m = folium.Map(location=[latitude, longitude], zoom_start=2)\n",
    "#m = folium.Map(location=[39.2904, -76.6122],zoom_start=12)\n",
    "for index, row in World_onehot_grouped_merged.iterrows():\n",
    "    #label = folium.Popup(str(poi) + ' Cluster ' + str(World_onehot_grouped_merged.loc[index,'total']), parse_html=True)\n",
    "    label = str(World_onehot_grouped_merged.loc[index,'City']) +',Venues= ' +str( World_onehot_grouped_merged.loc[index,'total'])\n",
    "    folium.CircleMarker([row['lat'], row['lng']],\n",
    "                    radius=3, popup= label, color=row['marker_color']).add_to(m)\n",
    "m\n",
    "    #print(World_onehot_grouped_merged)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us drow heat map for total hotels Worldwide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged['marker_color'] = pd.cut(World_onehot_grouped_merged['Hotel'], bins=3, \n",
    "                              labels=[ ' #FFA500','#1E90FF', 'red' ])\n",
    "m = folium.Map(location=[latitude, longitude], zoom_start=2)\n",
    "#m = folium.Map(location=[39.2904, -76.6122],zoom_start=12)\n",
    "for index, row in World_onehot_grouped_merged.iterrows():\n",
    "    #label = folium.Popup(str(poi) + ' Cluster ' + str(World_onehot_grouped_merged.loc[index,'total']), parse_html=True)\n",
    "    label = str(World_onehot_grouped_merged.loc[index,'City']) +',Hotel= ' +str( World_onehot_grouped_merged.loc[index,'Hotel'])\n",
    "    folium.CircleMarker([row['lat'], row['lng']],\n",
    "                    radius=3, popup= label, color=row['marker_color']).add_to(m)\n",
    "m\n",
    "    #print(World_onehot_grouped_merged)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us drow heat map for Coffeeshops  Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged['marker_color'] = pd.cut(World_onehot_grouped_merged['Coffee Shop'], bins=3, \n",
    "                              labels=[ ' #FFA500','#1E90FF', 'red' ])\n",
    "m = folium.Map(location=[latitude, longitude], zoom_start=2)\n",
    "#m = folium.Map(location=[39.2904, -76.6122],zoom_start=12)\n",
    "for index, row in World_onehot_grouped_merged.iterrows():\n",
    "    #label = folium.Popup(str(poi) + ' Cluster ' + str(World_onehot_grouped_merged.loc[index,'total']), parse_html=True)\n",
    "    label = str(World_onehot_grouped_merged.loc[index,'City']) +',Coffee Shop= ' +str( World_onehot_grouped_merged.loc[index,'Coffee Shop'])\n",
    "    folium.CircleMarker([row['lat'], row['lng']],\n",
    "                    radius=3, popup= label, color=row['marker_color']).add_to(m)\n",
    "m\n",
    "    #print(World_onehot_grouped_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detais of Cluster zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us drow heat map for Resrurants  Worldwide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged.loc [World_onehot_grouped_merged['World Capital_x']== 'Lisbon']\n",
    "#df.loc[df['column_name'] == some_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged['marker_color'] = pd.cut(World_onehot_grouped_merged['Restaurant'], bins=3, \n",
    "                              labels=[ ' #FFA500','#1E90FF', 'red' ])\n",
    "m = folium.Map(location=[latitude, longitude], zoom_start=2)\n",
    "#m = folium.Map(location=[39.2904, -76.6122],zoom_start=12)\n",
    "for index, row in World_onehot_grouped_merged.iterrows():\n",
    "    #label = folium.Popup(str(poi) + ' Cluster ' + str(World_onehot_grouped_merged.loc[index,'total']), parse_html=True)\n",
    "    label = str(World_onehot_grouped_merged.loc[index,'City']) +',Restaurant= ' + str( World_onehot_grouped_merged.loc[index,'Restaurant'])\n",
    "    folium.CircleMarker([row['lat'], row['lng']],\n",
    "                    radius=3, popup= label, color=row['marker_color']).add_to(m)\n",
    "m\n",
    "    #print(World_onehot_grouped_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Cluster_zero =  World_onehot_grouped_merged[World_onehot_grouped_merged['Cluster Labels']== 0.0 ]\n",
    "\n",
    "Cluster_zero.sort_values(by=['total'], inplace=True, ascending=False)\n",
    "Cluster_zero.reset_index(drop=True,inplace=True )\n",
    "Cluster_zero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_zero[['World Capital_x','Country','Coffee Shop', 'Hotel', 'Restaurant','total','Venue','Cluster Labels','1st Most Common Venue','2nd Most Common Venue','3rd Most Common Venue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features of Clster zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a vertical bar chart\n",
    "\n",
    "#Cluster_zero.plot.bar(x=\"City\", y=\"Visits\", rot=70, title=\"Number of tourist visits - Year 2018\");\n",
    "\n",
    "#plot.show(block=True);\n",
    "World_onehot_grouped_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_one =  World_onehot_grouped_merged[World_onehot_grouped_merged['Cluster Labels']== 1.0 ]\n",
    "Cluster_one.sort_values(by=['total'], inplace=True, ascending=False)\n",
    "Cluster_one.reset_index(drop=True,inplace=True )\n",
    "Cluster_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_one[['World Capital_x','Country','Coffee Shop', 'Hotel', 'Restaurant','total','Venue','Cluster Labels','1st Most Common Venue','2nd Most Common Venue','3rd Most Common Venue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Cluster_tow =  World_onehot_grouped_merged[World_onehot_grouped_merged['Cluster Labels']== 2.0 ]\n",
    "Cluster_tow.sort_values(by=['total'], inplace=True, ascending=False)\n",
    "Cluster_tow.reset_index(drop=True,inplace=True )\n",
    "Cluster_tow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_tow[['World Capital_x','Country','Coffee Shop', 'Hotel', 'Restaurant','total','Venue','Cluster Labels','1st Most Common Venue','2nd Most Common Venue','3rd Most Common Venue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depict Clusters' Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged_clusters=World_onehot_grouped_merged\n",
    "\n",
    "World_onehot_grouped_merged_clusters = World_onehot_grouped_merged_clusters.groupby(\"Cluster Labels\").agg ({'Coffee Shop': 'sum','Hotel': 'sum','Restaurant': 'sum', 'total': 'sum'})\n",
    "\n",
    "World_onehot_grouped_merged_clusters [['Coffee Shop', 'Hotel','Restaurant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_onehot_grouped_merged_clusters1=World_onehot_grouped_merged_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw  pie  charts\n",
    "\n",
    "#World_onehot_grouped_merged_clusters.plot.bar(x='Cluster Labels', y=['Coffee Shop',]'Coffee Shop''Hotel, rot=70, title=\"Number of venues per cluster\");\n",
    "\n",
    "World_onehot_grouped_merged_clusters.plot.pie(subplots=True, figsize=(15, 30),shadow = True,fontsize=12, autopct='%1.2f%%', startangle=0,legend=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "World_onehot_grouped_merged_clusters [['Hotel','Coffee Shop', 'Restaurant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = World_onehot_grouped_merged_clusters.plot.bar( rot=0,figsize = (6,3),fontsize =14)\n",
    "ax.set_ylabel('Count_Category')\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.5}'.format(Decimal(str(p.get_height()))), (p.get_x(), p.get_height()))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Agglomerative Clustering   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy import ndimage \n",
    "from scipy.cluster import hierarchy \n",
    "from scipy.spatial import distance_matrix \n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn import manifold, datasets \n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "from sklearn.datasets.samples_generator import make_blobs \n",
    "%matplotlib inline\n",
    "print ('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglom = AgglomerativeClustering(n_clusters = 3, linkage = 'single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglom.fit(World_grouped_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_grouped.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_grouped_clustering.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dendrogram Associated for the Agglomerative Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = distance_matrix(World_grouped[['Coffee Shop', 'Hotel', 'Restaurant']],World_grouped[['Coffee Shop', 'Hotel', 'Restaurant']]) \n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the linkage class from hierarchy, pass in the parameters:\n",
    "\n",
    "The distance matrix\n",
    "'complete' for complete linkage\n",
    "\n",
    "Save the result to a variable called Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import scipy.cluster.hierarchy\n",
    "Z = hierarchy.linkage(dist_matrix, 'average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Hierarchical clustering is typically visualized as a dendrogram as shown in the following cell. Each merge is represented by a horizontal line. The y-coordinate of the horizontal line is the similarity of the two clusters that were merged, where cities are viewed as singleton clusters. \n",
    "By moving up from the bottom layer to the top node, a dendrogram allows us to reconstruct the history of merges that resulted in the depicted clustering. \n",
    "\n",
    "Next, we will save the dendrogram to a variable called <b>dendro</b>. In doing this, the dendrogram will also be displayed.\n",
    "Using the <b> dendrogram </b> class from hierarchy, pass in the parameter:\n",
    "<ul> <li> Z </li> </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = pylab.figure(figsize=(18,80))\n",
    "def llf(id):\n",
    "    return '[%s ]' % (World_grouped['World Capital'][id],) \n",
    "    \n",
    "dendro = hierarchy.dendrogram(Z,  leaf_label_func=llf, leaf_rotation=0, leaf_font_size =12, orientation = 'right')\n",
    "\n",
    "#dendro = hierarchy.dendrogram(Z)\n",
    "#fig = pylab.figure(figsize=(8,60))\n",
    "#dendro = hierarchy.dendrogram(Z,  leaf_rotation=0, leaf_font_size =12, orientation = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label11= agglom.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.info(label11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "World_grouped['Clus_km'].value= ['label11']\n",
    "World_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Capstone Assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
